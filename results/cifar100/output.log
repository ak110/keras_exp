____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_1 (InputLayer)             (None, 32, 32, 3)     0                                            
____________________________________________________________________________________________________
start (Conv2D)                   (None, 32, 32, 128)   3456        input_1[0][0]                    
____________________________________________________________________________________________________
start_bn (BatchNormalization)    (None, 32, 32, 128)   512         start[0][0]                      
____________________________________________________________________________________________________
start_act (Activation)           (None, 32, 32, 128)   0           start_bn[0][0]                   
____________________________________________________________________________________________________
stage1_block_r0c1 (Conv2D)       (None, 32, 32, 128)   147456      start_act[0][0]                  
____________________________________________________________________________________________________
stage1_block_r0c1_bn (BatchNorma (None, 32, 32, 128)   512         stage1_block_r0c1[0][0]          
____________________________________________________________________________________________________
stage1_block_r0c1_act (Activatio (None, 32, 32, 128)   0           stage1_block_r0c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 32, 32, 128)   0           stage1_block_r0c1_act[0][0]      
____________________________________________________________________________________________________
stage1_block_r0c2 (Conv2D)       (None, 32, 32, 128)   147456      dropout_1[0][0]                  
____________________________________________________________________________________________________
stage1_block_r0c2_bn (BatchNorma (None, 32, 32, 128)   512         stage1_block_r0c2[0][0]          
____________________________________________________________________________________________________
add_1 (Add)                      (None, 32, 32, 128)   0           start_act[0][0]                  
                                                                   stage1_block_r0c2_bn[0][0]       
____________________________________________________________________________________________________
stage1_block_r1c1 (Conv2D)       (None, 32, 32, 128)   147456      add_1[0][0]                      
____________________________________________________________________________________________________
stage1_block_r1c1_bn (BatchNorma (None, 32, 32, 128)   512         stage1_block_r1c1[0][0]          
____________________________________________________________________________________________________
stage1_block_r1c1_act (Activatio (None, 32, 32, 128)   0           stage1_block_r1c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 32, 128)   0           stage1_block_r1c1_act[0][0]      
____________________________________________________________________________________________________
stage1_block_r1c2 (Conv2D)       (None, 32, 32, 128)   147456      dropout_2[0][0]                  
____________________________________________________________________________________________________
stage1_block_r1c2_bn (BatchNorma (None, 32, 32, 128)   512         stage1_block_r1c2[0][0]          
____________________________________________________________________________________________________
add_2 (Add)                      (None, 32, 32, 128)   0           add_1[0][0]                      
                                                                   stage1_block_r1c2_bn[0][0]       
____________________________________________________________________________________________________
stage1_block_r2c1 (Conv2D)       (None, 32, 32, 128)   147456      add_2[0][0]                      
____________________________________________________________________________________________________
stage1_block_r2c1_bn (BatchNorma (None, 32, 32, 128)   512         stage1_block_r2c1[0][0]          
____________________________________________________________________________________________________
stage1_block_r2c1_act (Activatio (None, 32, 32, 128)   0           stage1_block_r2c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 32, 32, 128)   0           stage1_block_r2c1_act[0][0]      
____________________________________________________________________________________________________
stage1_block_r2c2 (Conv2D)       (None, 32, 32, 128)   147456      dropout_3[0][0]                  
____________________________________________________________________________________________________
stage1_block_r2c2_bn (BatchNorma (None, 32, 32, 128)   512         stage1_block_r2c2[0][0]          
____________________________________________________________________________________________________
add_3 (Add)                      (None, 32, 32, 128)   0           add_2[0][0]                      
                                                                   stage1_block_r2c2_bn[0][0]       
____________________________________________________________________________________________________
stage1_block_r3c1 (Conv2D)       (None, 32, 32, 128)   147456      add_3[0][0]                      
____________________________________________________________________________________________________
stage1_block_r3c1_bn (BatchNorma (None, 32, 32, 128)   512         stage1_block_r3c1[0][0]          
____________________________________________________________________________________________________
stage1_block_r3c1_act (Activatio (None, 32, 32, 128)   0           stage1_block_r3c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 32, 32, 128)   0           stage1_block_r3c1_act[0][0]      
____________________________________________________________________________________________________
stage1_block_r3c2 (Conv2D)       (None, 32, 32, 128)   147456      dropout_4[0][0]                  
____________________________________________________________________________________________________
stage1_block_r3c2_bn (BatchNorma (None, 32, 32, 128)   512         stage1_block_r3c2[0][0]          
____________________________________________________________________________________________________
add_4 (Add)                      (None, 32, 32, 128)   0           add_3[0][0]                      
                                                                   stage1_block_r3c2_bn[0][0]       
____________________________________________________________________________________________________
stage1_block_r4c1 (Conv2D)       (None, 32, 32, 128)   147456      add_4[0][0]                      
____________________________________________________________________________________________________
stage1_block_r4c1_bn (BatchNorma (None, 32, 32, 128)   512         stage1_block_r4c1[0][0]          
____________________________________________________________________________________________________
stage1_block_r4c1_act (Activatio (None, 32, 32, 128)   0           stage1_block_r4c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 32, 32, 128)   0           stage1_block_r4c1_act[0][0]      
____________________________________________________________________________________________________
stage1_block_r4c2 (Conv2D)       (None, 32, 32, 128)   147456      dropout_5[0][0]                  
____________________________________________________________________________________________________
stage1_block_r4c2_bn (BatchNorma (None, 32, 32, 128)   512         stage1_block_r4c2[0][0]          
____________________________________________________________________________________________________
add_5 (Add)                      (None, 32, 32, 128)   0           add_4[0][0]                      
                                                                   stage1_block_r4c2_bn[0][0]       
____________________________________________________________________________________________________
stage1_block_r5c1 (Conv2D)       (None, 32, 32, 128)   147456      add_5[0][0]                      
____________________________________________________________________________________________________
stage1_block_r5c1_bn (BatchNorma (None, 32, 32, 128)   512         stage1_block_r5c1[0][0]          
____________________________________________________________________________________________________
stage1_block_r5c1_act (Activatio (None, 32, 32, 128)   0           stage1_block_r5c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 32, 32, 128)   0           stage1_block_r5c1_act[0][0]      
____________________________________________________________________________________________________
stage1_block_r5c2 (Conv2D)       (None, 32, 32, 128)   147456      dropout_6[0][0]                  
____________________________________________________________________________________________________
stage1_block_r5c2_bn (BatchNorma (None, 32, 32, 128)   512         stage1_block_r5c2[0][0]          
____________________________________________________________________________________________________
add_6 (Add)                      (None, 32, 32, 128)   0           add_5[0][0]                      
                                                                   stage1_block_r5c2_bn[0][0]       
____________________________________________________________________________________________________
batch_normalization_1 (BatchNorm (None, 32, 32, 128)   512         add_6[0][0]                      
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 32, 32, 128)   0           batch_normalization_1[0][0]      
____________________________________________________________________________________________________
stage1_tran_ex (Conv2D)          (None, 32, 32, 256)   32768       activation_1[0][0]               
____________________________________________________________________________________________________
stage1_tran_ex_bn (BatchNormaliz (None, 32, 32, 256)   1024        stage1_tran_ex[0][0]             
____________________________________________________________________________________________________
stage1_tran_ex_act (Activation)  (None, 32, 32, 256)   0           stage1_tran_ex_bn[0][0]          
____________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)   (None, 16, 16, 256)   0           stage1_tran_ex_act[0][0]         
____________________________________________________________________________________________________
stage2_block_r0c1 (Conv2D)       (None, 16, 16, 256)   589824      max_pooling2d_1[0][0]            
____________________________________________________________________________________________________
stage2_block_r0c1_bn (BatchNorma (None, 16, 16, 256)   1024        stage2_block_r0c1[0][0]          
____________________________________________________________________________________________________
stage2_block_r0c1_act (Activatio (None, 16, 16, 256)   0           stage2_block_r0c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_7 (Dropout)              (None, 16, 16, 256)   0           stage2_block_r0c1_act[0][0]      
____________________________________________________________________________________________________
stage2_block_r0c2 (Conv2D)       (None, 16, 16, 256)   589824      dropout_7[0][0]                  
____________________________________________________________________________________________________
stage2_block_r0c2_bn (BatchNorma (None, 16, 16, 256)   1024        stage2_block_r0c2[0][0]          
____________________________________________________________________________________________________
add_7 (Add)                      (None, 16, 16, 256)   0           max_pooling2d_1[0][0]            
                                                                   stage2_block_r0c2_bn[0][0]       
____________________________________________________________________________________________________
stage2_block_r1c1 (Conv2D)       (None, 16, 16, 256)   589824      add_7[0][0]                      
____________________________________________________________________________________________________
stage2_block_r1c1_bn (BatchNorma (None, 16, 16, 256)   1024        stage2_block_r1c1[0][0]          
____________________________________________________________________________________________________
stage2_block_r1c1_act (Activatio (None, 16, 16, 256)   0           stage2_block_r1c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_8 (Dropout)              (None, 16, 16, 256)   0           stage2_block_r1c1_act[0][0]      
____________________________________________________________________________________________________
stage2_block_r1c2 (Conv2D)       (None, 16, 16, 256)   589824      dropout_8[0][0]                  
____________________________________________________________________________________________________
stage2_block_r1c2_bn (BatchNorma (None, 16, 16, 256)   1024        stage2_block_r1c2[0][0]          
____________________________________________________________________________________________________
add_8 (Add)                      (None, 16, 16, 256)   0           add_7[0][0]                      
                                                                   stage2_block_r1c2_bn[0][0]       
____________________________________________________________________________________________________
stage2_block_r2c1 (Conv2D)       (None, 16, 16, 256)   589824      add_8[0][0]                      
____________________________________________________________________________________________________
stage2_block_r2c1_bn (BatchNorma (None, 16, 16, 256)   1024        stage2_block_r2c1[0][0]          
____________________________________________________________________________________________________
stage2_block_r2c1_act (Activatio (None, 16, 16, 256)   0           stage2_block_r2c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_9 (Dropout)              (None, 16, 16, 256)   0           stage2_block_r2c1_act[0][0]      
____________________________________________________________________________________________________
stage2_block_r2c2 (Conv2D)       (None, 16, 16, 256)   589824      dropout_9[0][0]                  
____________________________________________________________________________________________________
stage2_block_r2c2_bn (BatchNorma (None, 16, 16, 256)   1024        stage2_block_r2c2[0][0]          
____________________________________________________________________________________________________
add_9 (Add)                      (None, 16, 16, 256)   0           add_8[0][0]                      
                                                                   stage2_block_r2c2_bn[0][0]       
____________________________________________________________________________________________________
stage2_block_r3c1 (Conv2D)       (None, 16, 16, 256)   589824      add_9[0][0]                      
____________________________________________________________________________________________________
stage2_block_r3c1_bn (BatchNorma (None, 16, 16, 256)   1024        stage2_block_r3c1[0][0]          
____________________________________________________________________________________________________
stage2_block_r3c1_act (Activatio (None, 16, 16, 256)   0           stage2_block_r3c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_10 (Dropout)             (None, 16, 16, 256)   0           stage2_block_r3c1_act[0][0]      
____________________________________________________________________________________________________
stage2_block_r3c2 (Conv2D)       (None, 16, 16, 256)   589824      dropout_10[0][0]                 
____________________________________________________________________________________________________
stage2_block_r3c2_bn (BatchNorma (None, 16, 16, 256)   1024        stage2_block_r3c2[0][0]          
____________________________________________________________________________________________________
add_10 (Add)                     (None, 16, 16, 256)   0           add_9[0][0]                      
                                                                   stage2_block_r3c2_bn[0][0]       
____________________________________________________________________________________________________
stage2_block_r4c1 (Conv2D)       (None, 16, 16, 256)   589824      add_10[0][0]                     
____________________________________________________________________________________________________
stage2_block_r4c1_bn (BatchNorma (None, 16, 16, 256)   1024        stage2_block_r4c1[0][0]          
____________________________________________________________________________________________________
stage2_block_r4c1_act (Activatio (None, 16, 16, 256)   0           stage2_block_r4c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_11 (Dropout)             (None, 16, 16, 256)   0           stage2_block_r4c1_act[0][0]      
____________________________________________________________________________________________________
stage2_block_r4c2 (Conv2D)       (None, 16, 16, 256)   589824      dropout_11[0][0]                 
____________________________________________________________________________________________________
stage2_block_r4c2_bn (BatchNorma (None, 16, 16, 256)   1024        stage2_block_r4c2[0][0]          
____________________________________________________________________________________________________
add_11 (Add)                     (None, 16, 16, 256)   0           add_10[0][0]                     
                                                                   stage2_block_r4c2_bn[0][0]       
____________________________________________________________________________________________________
stage2_block_r5c1 (Conv2D)       (None, 16, 16, 256)   589824      add_11[0][0]                     
____________________________________________________________________________________________________
stage2_block_r5c1_bn (BatchNorma (None, 16, 16, 256)   1024        stage2_block_r5c1[0][0]          
____________________________________________________________________________________________________
stage2_block_r5c1_act (Activatio (None, 16, 16, 256)   0           stage2_block_r5c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_12 (Dropout)             (None, 16, 16, 256)   0           stage2_block_r5c1_act[0][0]      
____________________________________________________________________________________________________
stage2_block_r5c2 (Conv2D)       (None, 16, 16, 256)   589824      dropout_12[0][0]                 
____________________________________________________________________________________________________
stage2_block_r5c2_bn (BatchNorma (None, 16, 16, 256)   1024        stage2_block_r5c2[0][0]          
____________________________________________________________________________________________________
add_12 (Add)                     (None, 16, 16, 256)   0           add_11[0][0]                     
                                                                   stage2_block_r5c2_bn[0][0]       
____________________________________________________________________________________________________
batch_normalization_2 (BatchNorm (None, 16, 16, 256)   1024        add_12[0][0]                     
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 16, 16, 256)   0           batch_normalization_2[0][0]      
____________________________________________________________________________________________________
stage2_tran_ex (Conv2D)          (None, 16, 16, 512)   131072      activation_2[0][0]               
____________________________________________________________________________________________________
stage2_tran_ex_bn (BatchNormaliz (None, 16, 16, 512)   2048        stage2_tran_ex[0][0]             
____________________________________________________________________________________________________
stage2_tran_ex_act (Activation)  (None, 16, 16, 512)   0           stage2_tran_ex_bn[0][0]          
____________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)   (None, 8, 8, 512)     0           stage2_tran_ex_act[0][0]         
____________________________________________________________________________________________________
stage3_block_r0c1 (Conv2D)       (None, 8, 8, 512)     2359296     max_pooling2d_2[0][0]            
____________________________________________________________________________________________________
stage3_block_r0c1_bn (BatchNorma (None, 8, 8, 512)     2048        stage3_block_r0c1[0][0]          
____________________________________________________________________________________________________
stage3_block_r0c1_act (Activatio (None, 8, 8, 512)     0           stage3_block_r0c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_13 (Dropout)             (None, 8, 8, 512)     0           stage3_block_r0c1_act[0][0]      
____________________________________________________________________________________________________
stage3_block_r0c2 (Conv2D)       (None, 8, 8, 512)     2359296     dropout_13[0][0]                 
____________________________________________________________________________________________________
stage3_block_r0c2_bn (BatchNorma (None, 8, 8, 512)     2048        stage3_block_r0c2[0][0]          
____________________________________________________________________________________________________
add_13 (Add)                     (None, 8, 8, 512)     0           max_pooling2d_2[0][0]            
                                                                   stage3_block_r0c2_bn[0][0]       
____________________________________________________________________________________________________
stage3_block_r1c1 (Conv2D)       (None, 8, 8, 512)     2359296     add_13[0][0]                     
____________________________________________________________________________________________________
stage3_block_r1c1_bn (BatchNorma (None, 8, 8, 512)     2048        stage3_block_r1c1[0][0]          
____________________________________________________________________________________________________
stage3_block_r1c1_act (Activatio (None, 8, 8, 512)     0           stage3_block_r1c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_14 (Dropout)             (None, 8, 8, 512)     0           stage3_block_r1c1_act[0][0]      
____________________________________________________________________________________________________
stage3_block_r1c2 (Conv2D)       (None, 8, 8, 512)     2359296     dropout_14[0][0]                 
____________________________________________________________________________________________________
stage3_block_r1c2_bn (BatchNorma (None, 8, 8, 512)     2048        stage3_block_r1c2[0][0]          
____________________________________________________________________________________________________
add_14 (Add)                     (None, 8, 8, 512)     0           add_13[0][0]                     
                                                                   stage3_block_r1c2_bn[0][0]       
____________________________________________________________________________________________________
stage3_block_r2c1 (Conv2D)       (None, 8, 8, 512)     2359296     add_14[0][0]                     
____________________________________________________________________________________________________
stage3_block_r2c1_bn (BatchNorma (None, 8, 8, 512)     2048        stage3_block_r2c1[0][0]          
____________________________________________________________________________________________________
stage3_block_r2c1_act (Activatio (None, 8, 8, 512)     0           stage3_block_r2c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_15 (Dropout)             (None, 8, 8, 512)     0           stage3_block_r2c1_act[0][0]      
____________________________________________________________________________________________________
stage3_block_r2c2 (Conv2D)       (None, 8, 8, 512)     2359296     dropout_15[0][0]                 
____________________________________________________________________________________________________
stage3_block_r2c2_bn (BatchNorma (None, 8, 8, 512)     2048        stage3_block_r2c2[0][0]          
____________________________________________________________________________________________________
add_15 (Add)                     (None, 8, 8, 512)     0           add_14[0][0]                     
                                                                   stage3_block_r2c2_bn[0][0]       
____________________________________________________________________________________________________
stage3_block_r3c1 (Conv2D)       (None, 8, 8, 512)     2359296     add_15[0][0]                     
____________________________________________________________________________________________________
stage3_block_r3c1_bn (BatchNorma (None, 8, 8, 512)     2048        stage3_block_r3c1[0][0]          
____________________________________________________________________________________________________
stage3_block_r3c1_act (Activatio (None, 8, 8, 512)     0           stage3_block_r3c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_16 (Dropout)             (None, 8, 8, 512)     0           stage3_block_r3c1_act[0][0]      
____________________________________________________________________________________________________
stage3_block_r3c2 (Conv2D)       (None, 8, 8, 512)     2359296     dropout_16[0][0]                 
____________________________________________________________________________________________________
stage3_block_r3c2_bn (BatchNorma (None, 8, 8, 512)     2048        stage3_block_r3c2[0][0]          
____________________________________________________________________________________________________
add_16 (Add)                     (None, 8, 8, 512)     0           add_15[0][0]                     
                                                                   stage3_block_r3c2_bn[0][0]       
____________________________________________________________________________________________________
stage3_block_r4c1 (Conv2D)       (None, 8, 8, 512)     2359296     add_16[0][0]                     
____________________________________________________________________________________________________
stage3_block_r4c1_bn (BatchNorma (None, 8, 8, 512)     2048        stage3_block_r4c1[0][0]          
____________________________________________________________________________________________________
stage3_block_r4c1_act (Activatio (None, 8, 8, 512)     0           stage3_block_r4c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_17 (Dropout)             (None, 8, 8, 512)     0           stage3_block_r4c1_act[0][0]      
____________________________________________________________________________________________________
stage3_block_r4c2 (Conv2D)       (None, 8, 8, 512)     2359296     dropout_17[0][0]                 
____________________________________________________________________________________________________
stage3_block_r4c2_bn (BatchNorma (None, 8, 8, 512)     2048        stage3_block_r4c2[0][0]          
____________________________________________________________________________________________________
add_17 (Add)                     (None, 8, 8, 512)     0           add_16[0][0]                     
                                                                   stage3_block_r4c2_bn[0][0]       
____________________________________________________________________________________________________
stage3_block_r5c1 (Conv2D)       (None, 8, 8, 512)     2359296     add_17[0][0]                     
____________________________________________________________________________________________________
stage3_block_r5c1_bn (BatchNorma (None, 8, 8, 512)     2048        stage3_block_r5c1[0][0]          
____________________________________________________________________________________________________
stage3_block_r5c1_act (Activatio (None, 8, 8, 512)     0           stage3_block_r5c1_bn[0][0]       
____________________________________________________________________________________________________
dropout_18 (Dropout)             (None, 8, 8, 512)     0           stage3_block_r5c1_act[0][0]      
____________________________________________________________________________________________________
stage3_block_r5c2 (Conv2D)       (None, 8, 8, 512)     2359296     dropout_18[0][0]                 
____________________________________________________________________________________________________
stage3_block_r5c2_bn (BatchNorma (None, 8, 8, 512)     2048        stage3_block_r5c2[0][0]          
____________________________________________________________________________________________________
add_18 (Add)                     (None, 8, 8, 512)     0           add_17[0][0]                     
                                                                   stage3_block_r5c2_bn[0][0]       
____________________________________________________________________________________________________
batch_normalization_3 (BatchNorm (None, 8, 8, 512)     2048        add_18[0][0]                     
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 8, 8, 512)     0           batch_normalization_3[0][0]      
____________________________________________________________________________________________________
global_average_pooling2d_1 (Glob (None, 512)           0           activation_3[0][0]               
____________________________________________________________________________________________________
predictions (Dense)              (None, 100)           51300       global_average_pooling2d_1[0][0] 
====================================================================================================
Total params: 37,427,684
Trainable params: 37,402,596
Non-trainable params: 25,088
____________________________________________________________________________________________________
network depth: 40
Test loss:     0.9713863524794578
Test accuracy: 0.7957999831438065
Test error:    0.2042000168561935
Elapsed time = 72908 [s]
